{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 WorqHat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases the powerful capabilities of the WorqHat API for multimodal content generation. By leveraging audio, images, videos, and text files together in a single prompt, you can unlock a world of possibilities for creating engaging and informative blog posts.\n",
    "\n",
    "Imagine having a treasure trove of inspiration at your fingertips - voice memos you've recorded on the go, capturing your most brilliant ideas; images you've snapped that perfectly illustrate your points; and even relevant snippets from your previous articles. With the WorqHat API, you can seamlessly integrate all these elements to craft a truly immersive and compelling blog post.\n",
    "\n",
    "But the potential doesn't stop there. You can even extract features from the web to further enrich your content. Perhaps you want to include the latest statistics or a trending quote related to your topic. The WorqHat API can intelligently gather and incorporate this information, ensuring your blog post is always up-to-date and relevant.\n",
    "\n",
    "And for those seeking even more innovation, the possibilities are endless. Maybe you want to generate personalized content based on each reader's preferences, or create interactive elements that allow readers to explore your ideas in a hands-on way. With the WorqHat API's advanced capabilities, you can push the boundaries of what's possible in blog post creation.\n",
    "\n",
    "So whether you're a seasoned blogger looking to take your content to the next level, or just starting out and in need of some creative inspiration, this notebook will guide you through the process of leveraging the WorqHat API to generate truly remarkable blog posts. Get ready to unleash your creativity like never before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup WorqHat API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORQHAT_API_KEY = \"sk-caf41a358afe456286cd91f12c93199c\"\n",
    "WORQHAT_ENDPOINT_URL = \"https://api.worqhat.com/api/ai/content/v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will start working on the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import json\n",
    "import base64\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set any global variables here\n",
    "\n",
    "global_web_content = None\n",
    "global_files = []\n",
    "global_past_blog_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from the web or a YouTube video\n",
    "\n",
    "# Step 1: Ask the user for the source they want to use\n",
    "source = input(\"Enter the source you want to use (e.g., URL, YouTube video link, or leave blank to skip): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No source provided. Skipping data fetching.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: If the source is provided, fetch the data and pass it to the function\n",
    "def fetch_web_content(web_source):\n",
    "    global global_web_content\n",
    "\n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers['Authorization'] = f\"Bearer {WORQHAT_API_KEY}\"\n",
    "    headers['Content-Type'] = 'application/json'  # Ensure the content type is set to application/json\n",
    "\n",
    "    payload = json.dumps({\n",
    "        'question': f\"Get me a brief summary of the following source: {web_source}\",\n",
    "        'model': 'aicon-v4-alpha-160824',\n",
    "    })\n",
    "\n",
    "    response = requests.request(\"POST\", WORQHAT_ENDPOINT_URL, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        print(\"Response received:\", json.dumps(response_data, indent=4))\n",
    "        global_web_content = response_data['content']\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "if source:\n",
    "    # Fetch data from the web or a YouTube video based on the provided source\n",
    "    fetch_web_content(source)\n",
    "else:\n",
    "    print(\"No source provided. Skipping data fetching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PDF Files\n",
    "# global_files.append(('files', ('pdf.pdf', open('pdf.pdf', 'rb'), 'application/pdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Image Files\n",
    "global_files.append(('files', ('image.jpeg', open('image.jpeg', 'rb'), 'image/jpeg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Audio Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add past blog posts in the form of array of strings\n",
    "global_past_blog_posts.append(\"Embarking on the startup journey right out of college is a thrilling adventure ‚Äî one filled with potential yet filled with challenges. I know firsthand the hurdles of those initial stages: from the spark of an idea to the quest of releasing that first product version into the hands of the users. It‚Äôs a path of resilience, passion, and relentless pursuit of innovation. This is why we at WorqHat are excited to announce the WorqHat Startup Fund ‚Äî a source of support tailored for student founders, who are eager to leave a positive mark on the world through AI. üåçüí°Our commitment is deep-rooted in empowering early-stage startups to harness the transformative power of artificial intelligence. We envision a future where AI is not just a tool but a catalyst for global betterment. That said, here are highlights from WorqHat Startup Fund‚Äôs diligence process to help you get a mental template of what you could expect from us. We are sharing this because we believe it‚Äôs just as important for you to diligence your first institutional investor as it is for us to diligence you. The start of our investment process is sourcing. We know you can‚Äôt invest in the cream of the crop if you aren‚Äôt seeing a large section of the crop. So if you‚Äôre a founder, ask yourself how VC firms are going to find you? What‚Äôs your strategy to attract a VC/Funding firm at the sourcing stage? It‚Äôs literally the first step in diligence. If we do this wrong‚Äî we end up with bad matching. One of the things we do is benchmark our pipeline at regular intervals to make sure what we‚Äôre seeing is in line with what the market reports about startups and companies. Our next step is qualification. For us, those that are too early for us (pre revenue, pre product, just one big customer, etc.) go into a nurture bucket in our Datasheet for a drip feed of invitations to events, blog posts for founders, founders community and a quarterly follow-up from an analyst outbound call and sometimes even support with Technical Credits on Demand from all our Partners. All of this happens after the first Intro and Sourcing call. This is where we decide how further you are in your journey, as a Startup Fund, we can only personally support a small number of companies at any time. Those that are qualified ‚Äî which for us means they‚Äôre ready for their first institutional check, have growing revenue, eager current customers, and a software product that plays to our investment themes of financial inclusion ‚Äî our team collects a certain amount of information on their traction, operating docs, and previous fundraising history. This is a Due Diligence Request where we formally engage in reviewing that company‚Äìit‚Äôs gone beyond an intro call for us. If a startup hits our competitive benchmarks around growth, traction and funding, then the analyst sets up a meeting with the general partner. We try to do this at the company‚Äôs offices if possible. We have also made investments via Zoom and never met the founder in person. Bottomline, we love to see companies that can grow at least 20% quarter over quarter in customer-driven revenue.\")\n",
    "\n",
    "global_past_blog_posts.append(\"\"\"\n",
    "Creating loan agreements is a cornerstone task for financial institutions (FIs) such as credit unions, commercial banks, and brokerage firms. At the heart of this process lies the term sheet, a non-binding document that outlines the key terms and conditions of a prospective loan. However, drafting term sheets can be intricate and time-consuming, often requiring meticulous extraction and interpretation of data from diverse sources like call transcripts, company documents, and financial statements. WorqHat‚Äôs Generative AI Models\n",
    "With WorqHat‚Äôs cutting-edge Language Models, FIs can now automate and streamline the term sheet creation process, making it more efficient and accurate than ever before. In this post, we delve into the architecture of this innovative solution and explore how it optimizes the accuracy and precision of term sheet generation.\n",
    "\n",
    "A Two-Step Process: Information Extraction And Term Sheet Generation\n",
    "1. Information Extraction: WorqHat‚Äôs Fine-Tuned Answers model sifts through sources such as call transcripts and company documents to extract relevant information. Designed to understand the context and nuances of input data, this model identifies and extracts the most pertinent details related to the potential loan.\n",
    "\n",
    "2. Term Sheet Generation: The extracted information is processed through multiple AI model calls. Initially, the AI drafts a term sheet, ensuring it includes all necessary sections and clauses. Subsequently, the draft is critiqued for missing elements, while making necessary adjustments.\n",
    "\n",
    "3. Final Term Sheet: In the final phase, the AI synthesizes feedback and the original draft to create an enhanced version of the term sheet. This comprehensive document incorporates insights and suggestions from the critical analysis phase, ensuring it is accurate, complete, and tailored to the specific needs and standards of the financial institution.\n",
    "\n",
    "The WorqHat Advantage\n",
    "The final output is not only a term sheet with high fidelity to the original data (e.g., loan amount) but also highlights any key terms that may be missing (e.g., disclaimers). WorqHat AI can then create new terms for these sections based on the context, saving valuable time for human reviewers. This approach minimizes the risk of omissions or errors leading to legal or financial issues later.\n",
    "\n",
    "A crucial aspect of this workflow is the use of Contextual Answers, demonstrating the importance of using specialized tools for different use cases. In finance, where the stakes are high and terminology complex, employing a tool specifically designed for financial document generation is not just beneficial ‚Äî it‚Äôs essential. This methodology streamlines the term sheet generation process while enhancing the reliability and accuracy of financial agreements underpinning investments and loans.\n",
    "\n",
    "Getting Started with Term Sheet Automation\n",
    "In conclusion, integrating WorqHat‚Äôs Generative AI models into the term sheet generation process exemplifies the power of Task-Specific Models and general-purpose LLMs working together. By leveraging these models, financial institutions can ensure their term sheets are generated quickly, accurately, comprehensively, and tailored to specific needs. This approach streamlines the term sheet generation process underscoring the critical role of using the right tools for different tasks ‚Äî an essential lesson for success.\n",
    "\n",
    "WorqHat AI Fine-Tuned is now available in public preview. Start building today and transform the way you create financial term sheets! üåêüöÄ\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write the function to fetch the content from WorqHat API. We will make a POST request to the API with the files and the data.\n",
    "The data is the question we want to ask the AI. In our case, its the blog post we want to write about. Past blog posts are the training data. And any kind of audio, image, video or text files are the files we want to use to generate the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received: {\n",
      "    \"content\": \"## The Rise and Power of Pikachu: From Humble Beginnings to Global Icon\\n\\nPikachu. The name itself evokes a rush of nostalgia and excitement, conjuring up images of a tiny electric mouse with a mischievous grin. But how did this seemingly simple character become a global phenomenon, transcending the realm of video games to conquer hearts and minds worldwide?\\n\\nIt all began in 1996 with the release of **Pok\\u00e9mon Red and Green** in Japan.  Among a cast of quirky and colorful creatures, Pikachu stood out.  Its design, a simple yet endearing yellow mouse with reddish cheeks and a lightning bolt-shaped tail, resonated with audiences.  But it was more than just looks \\u2013  Pikachu\\u2019s playful personality and unique electric powers quickly captivated players, making it a fan favorite.\\n\\nHowever, Pikachu\\u2019s real breakthrough came with the **anime adaptation of Pok\\u00e9mon** in 1997.  The show focused on the journey of Ash Ketchum, a young trainer who partners with Pikachu on his quest to become a Pok\\u00e9mon master. The show's success was immediate and overwhelming, quickly establishing Pikachu as the face of the franchise.\\n\\nThe popularity of the anime helped to propel **Pok\\u00e9mon merchandise** into the stratosphere.  Everything from plush toys and trading cards to clothing and accessories became instant hits, solidifying Pikachu's status as a cultural icon.\\n\\nBut Pikachu's influence went beyond just merchandise.  The character's vibrant personality and electric powers resonated with audiences of all ages.  This led to **countless appearances in video games, movies, and even music**, further cementing its place in pop culture.\\n\\nToday, Pikachu remains one of the most recognizable and beloved characters in the world.  It has become a symbol of joy, friendship, and the power of believing in your dreams.  Its legacy extends beyond the world of Pok\\u00e9mon, inspiring countless artists, musicians, and even fashion designers.\\n\\nThe rise of Pikachu is a testament to the power of a simple yet captivating design, combined with a relatable personality and unique abilities.  But more than that, it represents the enduring appeal of a character who embodies the spirit of adventure, friendship, and the joy of exploring the unknown.  Pikachu's legacy continues to grow, reminding us all of the power of a little bit of electric charm. \\n\",\n",
      "    \"processingTime\": 7967.958158,\n",
      "    \"processingId\": \"46a522a1-8115-4440-8cbc-4cbe58d3c2b9\",\n",
      "    \"processingCount\": 4427,\n",
      "    \"conversation_id\": \"conv_1724694632728\",\n",
      "    \"model\": \"aicon-v4-nano-160824\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The function takes the files as input and returns the response from the WorqHat API.\n",
    "\n",
    "def fetch_worqhat_ai_content(input_files):\n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers['Authorization'] = f\"Bearer {WORQHAT_API_KEY}\"\n",
    "\n",
    "    training_content = \"\"\"\n",
    "Objective: Transform raw thoughts and ideas into polished, engaging blog posts that capture a writers unique style and voice.\n",
    "Input:\n",
    "Example Blog Posts (1-5): A user will provide examples of blog posts that resonate with their desired style and tone. These will guide you in understanding the preferences for word choice, sentence structure, and overall voice.\n",
    "Audio Clips: A user will share a selection of brainstorming thoughts and key points through audio recordings. They will talk freely and openly, as if they were explaining their ideas to a friend.\n",
    "Web Data: A user will provide the content of the website or the video. You will extract the relevant information from the website or the video and use it to generate the blog post.\n",
    "PDF Data: A user will provide the content of the PDF file. You will extract the relevant information from the PDF file and use it to generate the blog post.\n",
    "Image Data: A user will provide the content of the image. You will extract the relevant information from the image and use it to generate the blog post.\n",
    "Output:\n",
    "Blog Post Draft: A well-structured first draft of the blog post, suitable for platforms like Substack or LinkedIn.\n",
    "The draft will include:\n",
    "Clear and engaging writing: you will strive to make the writing clear, concise, and interesting for the target audience.\n",
    "Tone and style alignment: The language and style will closely match the examples provided, ensuring consistency with the desired voice.\n",
    "Logical flow and structure: The draft will be organized with clear sections based on the content of the post.\n",
    "Target word count: Aim for 500-800 words, but this can be adjusted based on user preferences.\n",
    "Process:\n",
    "Style Analysis: Carefully analyze the example blog posts provided by the user to identify key elements of their preferred style, including:\n",
    "Vocabulary and word choice: Formal vs. informal, technical terms, slang, etc.\n",
    "Sentence structure and length: Short and impactful vs. longer and descriptive sentences.\n",
    "Tone and voice: Humorous, serious, informative, persuasive, etc.\n",
    "Audio Transcription and Comprehension: Your audio clips will be transcribed with high accuracy. you will analyze them to extract key ideas, arguments, and supporting points.\n",
    "Draft Generation: Using the insights from the audio and the style guidelines from the examples, you will generate a first draft of the blog post. This draft will include all relevant sections with supporting arguments or evidence, and a great ending that ties everything together and makes the reader want to invest in future readings.\n",
    "Only generate the blog post based on the topic the user has asked for but use the past blog posts for tone and style, image and audio for content ideas.\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        'question': 'Draft a blog post on the Rise and Power of Pikachu',\n",
    "        'training_data': f\"Web Data: {global_web_content}\\n\\n Past Blog Posts: {' '.join(global_past_blog_posts)} \\n\\n Training Data: {training_content}\",\n",
    "        'model': 'aicon-v4-nano-160824',\n",
    "    }\n",
    "\n",
    "    response = requests.post(WORQHAT_ENDPOINT_URL, headers=headers, files=input_files, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received:\", json.dumps(response.json(), indent=4))\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "# Example usage\n",
    "fetch_worqhat_ai_content(global_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
